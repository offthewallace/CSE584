{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyOSP+EZl9izq5GpwvcBq93D",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/offthewallace/CSE584/blob/main/Sentence_complete_dataset_creation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Echg6ELif3Hj",
        "outputId": "0f124382-65c6-45ad-a36e-e5c1ae474436"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (16.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.8)\n",
            "Requirement already satisfied: huggingface-hub>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.13.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.22.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cL-T3oD2fSBL",
        "outputId": "c0b175dc-0390-41f0-c71a-5f075e457699"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer, AutoModelForCausalLM, AutoTokenizer\n",
        "import random\n",
        "import torch\n",
        "import torch\n",
        "\n",
        "# Check if GPU is available and set the device accordingly\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Check if GPU is available and set the device accordingly\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load the IMDB dataset\n",
        "def truncate_half_text(text):\n",
        "    \"\"\"\n",
        "    Truncates the text to the first 200 tokens, ensuring the result is non-empty.\n",
        "    If the text has fewer than 200 tokens, it returns the original text.\n",
        "    \"\"\"\n",
        "    words = text.split()\n",
        "\n",
        "    # Truncate to the first 200 tokens or return the original if it's shorter\n",
        "    truncated_text = ' '.join(words[:200])\n",
        "\n",
        "    return truncated_text if truncated_text else None\n",
        "\n",
        "\n",
        "def truncate_half_text2(text):\n",
        "    \"\"\"\n",
        "    Truncates the text to half its length, ensuring the result is non-empty.\n",
        "    \"\"\"\n",
        "    words = text.split()\n",
        "    if len(words) < 5:  # Skip if the text is too short to truncate\n",
        "        return text  # Return original text if it's too short\n",
        "    half_length = len(words) // 2\n",
        "    truncated_text = ' '.join(words[:half_length])\n",
        "    return truncated_text if truncated_text else None\n",
        "\n",
        "def add_prompt(truncated_text):\n",
        "    \"\"\"\n",
        "    Dynamically creates a prompt based on the truncated text.\n",
        "    \"\"\"\n",
        "    prompt = f'Complete this paragraph: \"{truncated_text}\"'\n",
        "    return prompt\n",
        "\n",
        "def batch_generate_completion(model, tokenizer, texts, max_new_tokens=200, top_k=50, top_p=0.9, temperature=0.8, repetition_penalty=1.2):\n",
        "    \"\"\"\n",
        "    Generate text completions in batches for a list of truncated texts using a specific model and tokenizer.\n",
        "    \"\"\"\n",
        "    if len(texts) == 0:\n",
        "        return []  # Return empty if the input batch is empty\n",
        "\n",
        "    # Tokenize the batch of texts\n",
        "    inputs = tokenizer(texts, return_tensors='pt', padding=True, truncation=True).to(device)\n",
        "\n",
        "    # Generate the completion and move output back to CPU for decoding\n",
        "    outputs = model.generate(\n",
        "        inputs['input_ids'],\n",
        "        attention_mask=inputs['attention_mask'],\n",
        "        max_new_tokens=max_new_tokens,\n",
        "        top_k=top_k,               # Use top-k sampling\n",
        "        top_p=top_p,               # Use nucleus sampling (top-p)\n",
        "        temperature=temperature,   # Adjust temperature for randomness\n",
        "        repetition_penalty=repetition_penalty,  # Penalize repetitive tokens\n",
        "        pad_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "\n",
        "    # Decode the output batch\n",
        "    return [tokenizer.decode(output, skip_special_tokens=True) for output in outputs]\n",
        "\n",
        "def generate_dataset_with_llms(dataset, models, tokenizers, num_samples=10, max_new_tokens=200, batch_size=8):\n",
        "    results = []\n",
        "    start_time = time.time()  # Start timer for total estimation\n",
        "\n",
        "    # Move models to GPU (cuda)\n",
        "    models = {name: model.to(device) for name, model in models.items()}\n",
        "\n",
        "    # Iterate through dataset in batches with progress tracking\n",
        "    for i in tqdm(range(0, num_samples, batch_size)):\n",
        "        # Get the current batch of examples (IMDB reviews are stored under the 'text' key)\n",
        "        batch_examples = dataset[i:i + batch_size]['ctx']\n",
        "\n",
        "        # Truncate the texts in the batch and dynamically add prompt\n",
        "        batch_truncated_texts = []\n",
        "        for example in batch_examples:\n",
        "\n",
        "            batch_truncated_texts.append(add_prompt(example))\n",
        "\n",
        "        # Skip empty or invalid truncated texts\n",
        "        if len(batch_truncated_texts) == 0:\n",
        "            print(f\"Skipping batch {i} due to empty truncated texts\")\n",
        "            continue\n",
        "\n",
        "        for model_name, model in models.items():\n",
        "            try:\n",
        "                # Time batch generation for each model\n",
        "                completion_start = time.time()\n",
        "\n",
        "                # Generate completions for the batch\n",
        "                completions = batch_generate_completion(model, tokenizers[model_name], batch_truncated_texts, max_new_tokens)\n",
        "\n",
        "                if len(completions) == 0:\n",
        "                    print(f\"No completions generated for batch {i} with model {model_name}\")\n",
        "                    continue  # Skip empty completions\n",
        "\n",
        "                completion_end = time.time()\n",
        "                completion_time = completion_end - completion_start\n",
        "                print(f\"Completion time for {model_name} batch: {completion_time:.2f} seconds\")\n",
        "\n",
        "                # Store the (xi, xj) pairs with corresponding LLM label\n",
        "                for truncated_text, completion in zip(batch_truncated_texts, completions):\n",
        "                    results.append({\n",
        "                        'xi': truncated_text,  # This will include the prompt with truncated text\n",
        "                        'xj': completion[len(truncated_text):].strip(),  # The actual completion generated by the model\n",
        "                        'llm': model_name\n",
        "                    })\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error generating completion with {model_name} for batch {i}: {e}\")\n",
        "                continue\n",
        "\n",
        "    end_time = time.time()  # End timer for total process\n",
        "\n",
        "    # Calculate time per sample and estimate total time\n",
        "    total_time = end_time - start_time\n",
        "    avg_time_per_sample = total_time / num_samples\n",
        "    total_samples = len(dataset)\n",
        "    estimated_total_time = avg_time_per_sample * total_samples\n",
        "\n",
        "    print(f\"\\nProcessed {num_samples} samples in {total_time:.2f} seconds.\")\n",
        "    print(f\"Average time per sample: {avg_time_per_sample:.2f} seconds.\")\n",
        "    print(f\"Estimated total time for {total_samples} samples: {estimated_total_time / 60:.2f} minutes.\")\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQ7yAouMnWcf",
        "outputId": "01e781dd-f200-4f00-80fe-1a1f60c6594b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer, AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "models = {\n",
        "    'gpt2': GPT2LMHeadModel.from_pretrained('gpt2'),  # 124M parameters\n",
        "    'gpt-neo': AutoModelForCausalLM.from_pretrained('EleutherAI/gpt-neo-125M'),  # 125M parameters\n",
        "    'distilgpt2': GPT2LMHeadModel.from_pretrained('distilgpt2'),  # 82M parameters\n",
        "    'qwen-2-0.5B': AutoModelForCausalLM.from_pretrained('Qwen/Qwen2-0.5B')  # 1.5B parameters\n",
        "}\n",
        "\n",
        "tokenizers = {\n",
        "    'gpt2': GPT2Tokenizer.from_pretrained('gpt2'),\n",
        "    'gpt-neo': AutoTokenizer.from_pretrained('EleutherAI/gpt-neo-125M'),\n",
        "    'distilgpt2': GPT2Tokenizer.from_pretrained('distilgpt2'),\n",
        "    'qwen-2-0.5B': AutoTokenizer.from_pretrained('Qwen/Qwen2-0.5B'),\n",
        "}\n",
        "\n",
        "# Set pad_token as eos_token for all models\n",
        "for model_name in models.keys():\n",
        "    tokenizers[model_name].pad_token = tokenizers[model_name].eos_token\n",
        "    tokenizers[model_name].padding_side = 'left'  # Set padding side to 'left'\n",
        "\n",
        "imdb_dataset = load_dataset(\"Rowan/hellaswag\", split='test')  # Use 'test' split for demonstration\n",
        "\n",
        "results = generate_dataset_with_llms(imdb_dataset, models, tokenizers, num_samples=10000, batch_size=200, max_new_tokens=200)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0Xyz-rnrj3m",
        "outputId": "f5291369-f0a3-42bd-bb21-2f4cd7af0c03"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/50 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completion time for gpt2 batch: 4.37 seconds\n",
            "Completion time for gpt-neo batch: 3.36 seconds\n",
            "Completion time for distilgpt2 batch: 2.80 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 1/50 [00:19<15:55, 19.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completion time for qwen-2-0.5B batch: 8.96 seconds\n",
            "Completion time for gpt2 batch: 4.39 seconds\n",
            "Completion time for gpt-neo batch: 3.41 seconds\n",
            "Completion time for distilgpt2 batch: 2.79 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 2/50 [00:39<15:39, 19.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completion time for qwen-2-0.5B batch: 9.02 seconds\n",
            "Completion time for gpt2 batch: 4.46 seconds\n",
            "Completion time for gpt-neo batch: 3.44 seconds\n",
            "Completion time for distilgpt2 batch: 2.84 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 3/50 [00:59<15:27, 19.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completion time for qwen-2-0.5B batch: 9.21 seconds\n",
            "Completion time for gpt2 batch: 4.81 seconds\n",
            "Completion time for gpt-neo batch: 3.61 seconds\n",
            "Completion time for distilgpt2 batch: 3.08 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 4/50 [01:20<15:34, 20.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completion time for qwen-2-0.5B batch: 9.68 seconds\n",
            "Completion time for gpt2 batch: 4.58 seconds\n",
            "Completion time for gpt-neo batch: 3.50 seconds\n",
            "Completion time for distilgpt2 batch: 2.91 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 5/50 [01:40<15:15, 20.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completion time for qwen-2-0.5B batch: 9.40 seconds\n",
            "Completion time for gpt2 batch: 4.52 seconds\n",
            "Completion time for gpt-neo batch: 3.47 seconds\n",
            "Completion time for distilgpt2 batch: 2.87 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 6/50 [02:00<14:51, 20.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completion time for qwen-2-0.5B batch: 9.27 seconds\n",
            "Completion time for gpt2 batch: 4.55 seconds\n",
            "Completion time for gpt-neo batch: 3.50 seconds\n",
            "Completion time for distilgpt2 batch: 2.90 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 7/50 [02:21<14:32, 20.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completion time for qwen-2-0.5B batch: 9.39 seconds\n",
            "Completion time for gpt2 batch: 4.63 seconds\n",
            "Completion time for gpt-neo batch: 3.53 seconds\n",
            "Completion time for distilgpt2 batch: 2.94 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 8/50 [02:41<14:15, 20.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completion time for qwen-2-0.5B batch: 9.44 seconds\n",
            "Completion time for gpt2 batch: 4.61 seconds\n",
            "Completion time for gpt-neo batch: 3.50 seconds\n",
            "Completion time for distilgpt2 batch: 2.93 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 9/50 [03:02<13:58, 20.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completion time for qwen-2-0.5B batch: 9.55 seconds\n",
            "Completion time for gpt2 batch: 4.42 seconds\n",
            "Completion time for gpt-neo batch: 3.42 seconds\n",
            "Completion time for distilgpt2 batch: 2.85 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 10/50 [03:22<13:29, 20.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completion time for qwen-2-0.5B batch: 9.11 seconds\n",
            "Completion time for gpt2 batch: 4.83 seconds\n",
            "Completion time for gpt-neo batch: 3.65 seconds\n",
            "Completion time for distilgpt2 batch: 3.04 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 11/50 [03:43<13:23, 20.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completion time for qwen-2-0.5B batch: 9.86 seconds\n",
            "Completion time for gpt2 batch: 4.49 seconds\n",
            "Completion time for gpt-neo batch: 3.44 seconds\n",
            "Completion time for distilgpt2 batch: 2.85 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 12/50 [04:03<12:56, 20.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completion time for qwen-2-0.5B batch: 9.26 seconds\n",
            "Completion time for gpt2 batch: 4.60 seconds\n",
            "Completion time for gpt-neo batch: 3.50 seconds\n",
            "Completion time for distilgpt2 batch: 2.90 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 13/50 [04:23<12:35, 20.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completion time for qwen-2-0.5B batch: 9.41 seconds\n",
            "Completion time for gpt2 batch: 4.53 seconds\n",
            "Completion time for gpt-neo batch: 3.48 seconds\n",
            "Completion time for distilgpt2 batch: 2.87 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 14/50 [04:43<12:11, 20.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completion time for qwen-2-0.5B batch: 9.22 seconds\n",
            "Completion time for gpt2 batch: 4.67 seconds\n",
            "Completion time for gpt-neo batch: 3.55 seconds\n",
            "Completion time for distilgpt2 batch: 2.95 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 15/50 [05:04<11:54, 20.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completion time for qwen-2-0.5B batch: 9.50 seconds\n",
            "Completion time for gpt2 batch: 4.38 seconds\n",
            "Completion time for gpt-neo batch: 3.38 seconds\n",
            "Completion time for distilgpt2 batch: 2.80 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 16/50 [05:24<11:26, 20.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completion time for qwen-2-0.5B batch: 9.02 seconds\n",
            "Completion time for gpt2 batch: 4.32 seconds\n",
            "Completion time for gpt-neo batch: 3.37 seconds\n",
            "Completion time for distilgpt2 batch: 2.75 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▍      | 17/50 [05:43<10:57, 19.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completion time for qwen-2-0.5B batch: 8.91 seconds\n",
            "Completion time for gpt2 batch: 5.27 seconds\n",
            "Completion time for gpt-neo batch: 3.84 seconds\n",
            "Completion time for distilgpt2 batch: 3.31 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 18/50 [06:06<11:07, 20.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completion time for qwen-2-0.5B batch: 10.57 seconds\n",
            "Completion time for gpt2 batch: 5.23 seconds\n",
            "Completion time for gpt-neo batch: 3.78 seconds\n",
            "Completion time for distilgpt2 batch: 3.32 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 19/50 [06:29<11:03, 21.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completion time for qwen-2-0.5B batch: 10.35 seconds\n",
            "Completion time for gpt2 batch: 5.25 seconds\n",
            "Completion time for gpt-neo batch: 3.78 seconds\n",
            "Completion time for distilgpt2 batch: 3.33 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 20/50 [06:52<10:55, 21.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completion time for qwen-2-0.5B batch: 10.56 seconds\n",
            "Completion time for gpt2 batch: 5.21 seconds\n",
            "Completion time for gpt-neo batch: 3.80 seconds\n",
            "Completion time for distilgpt2 batch: 3.31 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 21/50 [07:15<10:42, 22.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completion time for qwen-2-0.5B batch: 10.52 seconds\n",
            "Completion time for gpt2 batch: 5.45 seconds\n",
            "Completion time for gpt-neo batch: 3.91 seconds\n",
            "Completion time for distilgpt2 batch: 3.44 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 22/50 [07:39<10:38, 22.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completion time for qwen-2-0.5B batch: 11.54 seconds\n",
            "Completion time for gpt2 batch: 5.18 seconds\n",
            "Completion time for gpt-neo batch: 3.77 seconds\n",
            "Completion time for distilgpt2 batch: 3.28 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 23/50 [08:02<10:15, 22.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completion time for qwen-2-0.5B batch: 10.55 seconds\n",
            "Completion time for gpt2 batch: 5.26 seconds\n",
            "Completion time for gpt-neo batch: 3.81 seconds\n",
            "Completion time for distilgpt2 batch: 3.33 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 24/50 [08:25<09:53, 22.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completion time for qwen-2-0.5B batch: 10.48 seconds\n",
            "Completion time for gpt2 batch: 5.23 seconds\n",
            "Completion time for gpt-neo batch: 3.82 seconds\n",
            "Completion time for distilgpt2 batch: 3.31 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 25/50 [08:48<09:31, 22.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completion time for qwen-2-0.5B batch: 10.60 seconds\n",
            "Completion time for gpt2 batch: 5.31 seconds\n",
            "Completion time for gpt-neo batch: 3.86 seconds\n",
            "Completion time for distilgpt2 batch: 3.36 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 26/50 [09:11<09:10, 22.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completion time for qwen-2-0.5B batch: 10.59 seconds\n",
            "Completion time for gpt2 batch: 5.15 seconds\n",
            "Completion time for gpt-neo batch: 3.75 seconds\n",
            "Completion time for distilgpt2 batch: 3.31 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 27/50 [09:33<08:44, 22.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completion time for qwen-2-0.5B batch: 10.30 seconds\n",
            "Completion time for gpt2 batch: 5.31 seconds\n",
            "Completion time for gpt-neo batch: 3.84 seconds\n",
            "Completion time for distilgpt2 batch: 3.36 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 28/50 [09:56<08:23, 22.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completion time for qwen-2-0.5B batch: 10.59 seconds\n",
            "Completion time for gpt2 batch: 5.32 seconds\n",
            "Completion time for gpt-neo batch: 3.86 seconds\n",
            "Completion time for distilgpt2 batch: 3.36 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 29/50 [10:19<08:01, 22.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completion time for qwen-2-0.5B batch: 10.49 seconds\n",
            "Completion time for gpt2 batch: 5.22 seconds\n",
            "Completion time for gpt-neo batch: 3.81 seconds\n",
            "Completion time for distilgpt2 batch: 3.31 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 30/50 [10:42<07:38, 22.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completion time for qwen-2-0.5B batch: 10.52 seconds\n",
            "Completion time for gpt2 batch: 5.22 seconds\n",
            "Completion time for gpt-neo batch: 3.79 seconds\n",
            "Completion time for distilgpt2 batch: 3.31 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 31/50 [11:05<07:14, 22.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completion time for qwen-2-0.5B batch: 10.35 seconds\n",
            "Completion time for gpt2 batch: 5.33 seconds\n",
            "Completion time for gpt-neo batch: 3.89 seconds\n",
            "Completion time for distilgpt2 batch: 3.38 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 32/50 [11:28<06:52, 22.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completion time for qwen-2-0.5B batch: 10.38 seconds\n",
            "Completion time for gpt2 batch: 5.23 seconds\n",
            "Completion time for gpt-neo batch: 3.80 seconds\n",
            "Completion time for distilgpt2 batch: 3.32 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|██████▌   | 33/50 [11:51<06:28, 22.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completion time for qwen-2-0.5B batch: 10.48 seconds\n",
            "Completion time for gpt2 batch: 5.25 seconds\n",
            "Completion time for gpt-neo batch: 3.82 seconds\n",
            "Completion time for distilgpt2 batch: 3.33 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 34/50 [12:14<06:06, 22.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completion time for qwen-2-0.5B batch: 10.50 seconds\n",
            "Completion time for gpt2 batch: 5.19 seconds\n",
            "Completion time for gpt-neo batch: 3.81 seconds\n",
            "Completion time for distilgpt2 batch: 3.30 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 35/50 [12:36<05:43, 22.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completion time for qwen-2-0.5B batch: 10.58 seconds\n",
            "Completion time for gpt2 batch: 5.31 seconds\n",
            "Completion time for gpt-neo batch: 3.87 seconds\n",
            "Completion time for distilgpt2 batch: 3.37 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▏  | 36/50 [13:00<05:21, 22.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completion time for qwen-2-0.5B batch: 10.67 seconds\n",
            "Completion time for gpt2 batch: 5.27 seconds\n",
            "Completion time for gpt-neo batch: 3.85 seconds\n",
            "Completion time for distilgpt2 batch: 3.34 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▍  | 37/50 [13:23<04:58, 22.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completion time for qwen-2-0.5B batch: 10.51 seconds\n",
            "Completion time for gpt2 batch: 5.22 seconds\n",
            "Completion time for gpt-neo batch: 3.85 seconds\n",
            "Completion time for distilgpt2 batch: 3.29 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▌  | 38/50 [13:45<04:35, 22.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completion time for qwen-2-0.5B batch: 10.39 seconds\n",
            "Completion time for gpt2 batch: 5.20 seconds\n",
            "Completion time for gpt-neo batch: 3.85 seconds\n",
            "Completion time for distilgpt2 batch: 3.30 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 39/50 [14:08<04:11, 22.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completion time for qwen-2-0.5B batch: 10.47 seconds\n",
            "Completion time for gpt2 batch: 5.21 seconds\n",
            "Completion time for gpt-neo batch: 3.83 seconds\n",
            "Completion time for distilgpt2 batch: 3.30 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 40/50 [14:31<03:49, 22.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completion time for qwen-2-0.5B batch: 10.71 seconds\n",
            "Completion time for gpt2 batch: 5.24 seconds\n",
            "Completion time for gpt-neo batch: 3.81 seconds\n",
            "Completion time for distilgpt2 batch: 3.31 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%|████████▏ | 41/50 [14:54<03:26, 22.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completion time for qwen-2-0.5B batch: 10.58 seconds\n",
            "Completion time for gpt2 batch: 5.24 seconds\n",
            "Completion time for gpt-neo batch: 3.82 seconds\n",
            "Completion time for distilgpt2 batch: 3.33 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 42/50 [15:17<03:03, 22.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completion time for qwen-2-0.5B batch: 10.51 seconds\n",
            "Completion time for gpt2 batch: 5.32 seconds\n",
            "Completion time for gpt-neo batch: 3.92 seconds\n",
            "Completion time for distilgpt2 batch: 3.40 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 43/50 [15:41<02:41, 23.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completion time for qwen-2-0.5B batch: 10.67 seconds\n",
            "Completion time for gpt2 batch: 5.31 seconds\n",
            "Completion time for gpt-neo batch: 3.87 seconds\n",
            "Completion time for distilgpt2 batch: 3.36 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 44/50 [16:04<02:18, 23.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completion time for qwen-2-0.5B batch: 10.58 seconds\n",
            "Completion time for gpt2 batch: 5.24 seconds\n",
            "Completion time for gpt-neo batch: 3.82 seconds\n",
            "Completion time for distilgpt2 batch: 3.32 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 45/50 [16:27<01:55, 23.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completion time for qwen-2-0.5B batch: 10.52 seconds\n",
            "Completion time for gpt2 batch: 5.33 seconds\n",
            "Completion time for gpt-neo batch: 3.86 seconds\n",
            "Completion time for distilgpt2 batch: 3.37 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 46/50 [16:50<01:32, 23.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completion time for qwen-2-0.5B batch: 10.49 seconds\n",
            "Completion time for gpt2 batch: 5.25 seconds\n",
            "Completion time for gpt-neo batch: 3.84 seconds\n",
            "Completion time for distilgpt2 batch: 3.33 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 47/50 [17:13<01:08, 23.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completion time for qwen-2-0.5B batch: 10.49 seconds\n",
            "Completion time for gpt2 batch: 5.26 seconds\n",
            "Completion time for gpt-neo batch: 3.83 seconds\n",
            "Completion time for distilgpt2 batch: 3.33 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 48/50 [17:35<00:45, 22.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completion time for qwen-2-0.5B batch: 10.53 seconds\n",
            "Completion time for gpt2 batch: 5.27 seconds\n",
            "Completion time for gpt-neo batch: 3.85 seconds\n",
            "Completion time for distilgpt2 batch: 3.34 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 49/50 [17:59<00:23, 23.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completion time for qwen-2-0.5B batch: 10.59 seconds\n",
            "Completion time for gpt2 batch: 5.27 seconds\n",
            "Completion time for gpt-neo batch: 3.86 seconds\n",
            "Completion time for distilgpt2 batch: 3.34 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [18:22<00:00, 22.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completion time for qwen-2-0.5B batch: 10.73 seconds\n",
            "\n",
            "Processed 10000 samples in 1103.56 seconds.\n",
            "Average time per sample: 0.11 seconds.\n",
            "Estimated total time for 10003 samples: 18.40 minutes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Convert results to a DataFrame\n",
        "df = pd.DataFrame(results)\n",
        "\n",
        "# Save to CSV\n",
        "df.to_csv(\"sentence_complete2.csv\", index=False)\n",
        "\n",
        "print(\"Dataset saved as 'llm_wikitext_completions.csv'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uaAysJtYgIgf",
        "outputId": "b1022239-4f76-4888-8f4e-87cd24e90071"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset saved as 'llm_wikitext_completions.csv'\n"
          ]
        }
      ]
    }
  ]
}